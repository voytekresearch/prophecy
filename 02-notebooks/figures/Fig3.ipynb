{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a89232d3-68a0-47fb-9eb6-4081094bbf19",
   "metadata": {},
   "source": [
    "# Figure 3\n",
    "\n",
    "**Figure 3 | Spearman correlation strength of sEEG to simulated LFP.** (A) Bottom-up sensory input model similarity to neural signals. sEEG electrode color intensity represents the similarity of the neural signal to the LFP simulated from the bottom-up model. Similarity is quantified as the absolute value of the median Spearman coefficient (ρ) across all included trials. Similarity is z-scored across n = 7 participants. Electrode size represents the FDR corrected p-value from a 1000-fold permutation test. (B) Similarity values differed between models and controls across all highly significant (p < 0.001, permutation test) cortical electrodes (Friedman test: p = 0.018). Post-hoc, the bottom-up model was significantly less similar to sEEG than the audio envelope ($\\rho_{bottom-up}$ median (Q1, Q3) = 0.026 (0.015, 0.038); $\\rho_{control}$ = 0.026 (0.012, 0.048); n = 364; two-sided Wilcoxon signed-rank test: $p_{adj}$ < $10^{-5}$). (C) Top-down bias model similarity to neural signals. (D) Post-hoc, the top-down model was significantly more similar to sEEG than the audio envelope ($\\rho_{top-down}$ = 0.028 (0.014, 0.050); $\\rho_{control}$ = 0.018 (0.008, 0.034); n = 350; two-sided Wilcoxon signed-rank test: $p_{adj}$ < $10^{-5}$). (E) Dynamical systems SAMy (y-unit) model similarity to neural signals. (F) Post-hoc, SAMy had significantly higher similarity values than the audio envelope control condition ($\\rho_{SAMy}$ = 0.034 (0.017, 0.061); $\\rho_{control}$ = 0.022 (0.010, 0.041); n = 449; two-sided Wilcoxon signed-rank test: $p_{adj}$ < $10^{-5}$). SAMy had higher similarity values than both the top-down model ($\\rho_{SAMy}$ = 0.034 (0.017, 0.061), $n_{SAMy}$ = 449; $\\rho_{bottom-up}$ = 0.028 (0.014, 0.050), $n_{top-down}$ = 350; two-sided Wilcoxon signed-rank test: $p_{adj}$ = 0.003) and the bottom-up model ($\\rho_{SAMy}$ = 0.034 (0.017, 0.061), $n_{SAMy}$ = 449; $\\rho_{bottom-up}$ = 0.026 (0.015, 0.038), $n_{bottom-up}$ = 364; two-sided Wilcoxon signed rank test: $p_{adj}$ < $10^{-5}$). (G) Similarity values of highly significant (p < 0.001) electrodes by cortical region. Absolute value of the median $\\rho$ coefficient is plotted by cortical region, based on a coarse regional atlas. Horizontal black bars represent region-wise medians. Statistics for within-region model comparisons are available in Table 1. See Supp. Fig. 1 for paired plots of model and control similarity values at the same electrode. All p-values are adjusted for multiple comparisons with a Holm-Bonferroni correction. Stars indicate significant differences between models within a region (∗ p < 0.05, ∗∗ p < 0.01, ∗∗∗ p < 0.001). All participants had sEEG coverage in the prefrontal and superior temporal cortex, but sEEG from other regions represents a subset of participants.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f1c352-98aa-4b9c-9f79-b552ceda37f8",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e0f91e8-cfb9-4d3a-a53c-536d78e6fde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import mne\n",
    "from scipy.stats import zscore, false_discovery_control\n",
    "\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2e7b8f-a8fa-4a68-a200-40ba0c56a891",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a6c28d9-725d-46af-9e93-626c73ffe0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NormalizeData(data):\n",
    "    return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "\n",
    "def classify_pval(val):\n",
    "    \"\"\"classify p-value for sensor size\"\"\"\n",
    "    if val > 0.05:\n",
    "        return 0.5\n",
    "    elif 0.001 < val <= 0.05:\n",
    "        return 0.85\n",
    "    elif val <= 0.001:\n",
    "        return 1.25\n",
    "\n",
    "def load_fif_epo(subj):\n",
    "    \"\"\"load iEEG epo.fif file\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    subj : str\n",
    "        subject ID number        \n",
    "    Returns:\n",
    "    --------\n",
    "    epo : object\n",
    "        instance of MNE Epochs \n",
    "    \"\"\"\n",
    "    \n",
    "    path = '../../00-data/simulated_sEEG/sim/'+subj+'_sim_epo.fif' #'/Users/sydneysmith/Projects/PrOPHEcy/PrOPHEcy/00-data/epo_fifs/' + subj + '_BIP_epo.fif'\n",
    "    epo = mne.read_epochs(path, preload=True)\n",
    "    \n",
    "    return epo\n",
    "\n",
    "def plot_brain_model_fits(patients, SDids, metric, hemi, view):\n",
    "    \"\"\"Plots electrode locations from all iEEG recording onto single template brain\n",
    "    NO NORMALIZATION per subject\n",
    "    \n",
    "    Paramters:\n",
    "    ----------\n",
    "    patients : list\n",
    "        list of patient IDs to be plotted\n",
    "    SDids : list\n",
    "        list of strings of patient IDs from UCSD Health\n",
    "    metric : str\n",
    "        metric to plot or None\n",
    "    hemi : str\n",
    "        hemisphere to plot, \"left\" or \"right\"\n",
    "    view : str\n",
    "        view to plot, \"medial\" or \"lateral\"\n",
    "    \n",
    "        \n",
    "    \"\"\"\n",
    "    subjects_dir = '../../00-data/freesurfer'#'/Users/sydneysmith/Projects/PrOPHEcy/3dSlicer_localization'\n",
    "    \n",
    "    # make brain surface\n",
    "    brain = mne.viz.Brain(\n",
    "            'fsaverage',\n",
    "            title = 'Median '+metric+', n='+str(len(SDids)),\n",
    "            hemi = 'both',\n",
    "            surf='pial',\n",
    "            subjects_dir=subjects_dir,\n",
    "            cortex=\"low_contrast\",\n",
    "            alpha=0.2,\n",
    "            background=\"white\",\n",
    "            units = 'm'\n",
    "        )\n",
    "\n",
    "    # load median model fits & pvals\n",
    "    pval_dfs = []\n",
    "    for patient in patients:\n",
    "        pval_path = '../../03-results/perm_test/p_vals/'+patient+'_pvals.csv' #'/Users/sydneysmith/Projects/PrOPHEcy/PrOPHEcy/03-results/ieeg/perm_test/n_1000/p_vals/'+patient+'_pvals.csv'\n",
    "        pval_df = pd.read_csv(pval_path)\n",
    "        pval_df['patient'] = np.tile(patient, len(pval_df))\n",
    "        pval_dfs.append(pval_df)\n",
    "\n",
    "    all_pval_df = pd.concat(pval_dfs)\n",
    "\n",
    "    # zscore metric across all patients\n",
    "    all_pval_df[metric+'_zscore'] = zscore(abs(all_pval_df[metric].values))\n",
    "    \n",
    "    # loop through patients and add sensors (color code for metric value)\n",
    "    for patient, SDid in zip(patients, SDids):\n",
    "\n",
    "        # load epochs object for one patient\n",
    "        epochs = load_fif_epo(patient)\n",
    "        epochs = epochs.pick_types(seeg=True)\n",
    "        epochs = epochs.drop_channels(epochs.info['bads'])\n",
    "\n",
    "        # load similarity metrics for one patient\n",
    "        model_path = '../../03-results/model_comparison/subj_'+patient+'_model_comparison.csv' #'/Users/sydneysmith/Projects/PrOPHEcy/PrOPHEcy/03-results/ieeg/model_comparison/subj_'+patient+'_model_comparison.csv'\n",
    "        df = pd.read_csv(model_path) \n",
    "\n",
    "        subject = 'FSURF_'+SDid\n",
    "\n",
    "        # channel locations\n",
    "        montage = epochs.get_montage()\n",
    "        ch_names = montage.ch_names\n",
    "        ch_pos = montage.get_positions()['ch_pos'].values()\n",
    "        ch_pos = list(ch_pos)\n",
    "        ch_pos_new = [pos/1000 for pos in ch_pos] # adjust to meter scaling from mm\n",
    "\n",
    "        # identify hemisphere from channel name\n",
    "        ch_names_hemi = ['right' if (name[0]=='R') or (name[0]=='D') else 'left' for name in ch_names]\n",
    "        ch_names_right = np.array(ch_names)[np.array([hemi=='right' for hemi in ch_names_hemi])]\n",
    "        ch_names_left = np.array(ch_names)[np.array([hemi=='left' for hemi in ch_names_hemi])]\n",
    "        \n",
    "        if metric == 'None':\n",
    "            vals = None\n",
    "        else:\n",
    "            # create df with median values across all channels\n",
    "            median_df = pd.DataFrame(df.groupby('channel', sort=False, as_index=False)[metric].median())\n",
    "            \n",
    "            # get this patient's chunk of model dataframe\n",
    "            subj_pval_df = all_pval_df[all_pval_df['patient']==patient][['channel', metric+'_pval', metric+'_zscore']]\n",
    "\n",
    "            # FDR correction\n",
    "            subj_pval_df['FDR_pval'] = false_discovery_control(subj_pval_df[metric+'_pval'].values, method='bh')\n",
    "\n",
    "            # merge & compute sensor size factors\n",
    "            median_df = pd.merge(median_df, subj_pval_df, how='left', on='channel')\n",
    "            median_df['size_factor'] = median_df['FDR_pval'].apply(classify_pval)\n",
    "            \n",
    "            # select data from desired hemisphere\n",
    "            if hemi=='right':\n",
    "                median_df = median_df[median_df['channel'].isin(ch_names_right)]\n",
    "                #vals = median_df[metric+'_normalized'].values\n",
    "                vals = median_df[metric+'_zscore'].values\n",
    "            elif hemi=='left':\n",
    "                median_df = median_df[median_df['channel'].isin(ch_names_left)]\n",
    "                #vals = median_df[metric+'_normalized'].values\n",
    "                vals = median_df[metric+'_zscore'].values\n",
    "                \n",
    "        if len(vals)==0:\n",
    "            continue\n",
    "        else:\n",
    "            if metric == 'raw_SAM_y_rho':\n",
    "                colors = [cm.RdPu(i) for i in NormalizeData(vals)]\n",
    "            elif metric == 'raw_top_rho':\n",
    "                colors = [cm.OrRd(i) for i in NormalizeData(vals)]\n",
    "            elif metric == 'raw_btm_rho':\n",
    "                colors = [cm.Blues(i) for i in NormalizeData(vals)]\n",
    "            elif metric == 'raw_SAM_i_rho':\n",
    "                colors = [cm.Greens(i) for i in NormalizeData(vals)]\n",
    "            elif metric == 'raw_SAM_e_rho':\n",
    "                colors = [cm.YlOrBr(i) for i in NormalizeData(vals)]\n",
    "            elif metric == 'None':\n",
    "                colors = 'black'\n",
    "            else:\n",
    "                print('metric is '+metric)\n",
    "                colors = [cm.viridis(i) for i in NormalizeData(vals)]\n",
    "        \n",
    "        features = ['raw_top_r', 'raw_top_rho',\n",
    "            'raw_btm_r', 'raw_btm_rho', \n",
    "            'raw_comb_r', 'raw_comb_rho',\n",
    "            'raw_SAM_y_r', 'raw_SAM_y_rho',\n",
    "            'raw_SAM_e_r', 'raw_SAM_e_rho', \n",
    "            'raw_SAM_i_r', 'raw_SAM_i_rho']\n",
    "\n",
    "    \n",
    "        if patient == '1014':\n",
    "            ch_pos_new = np.asarray(ch_pos_new)\n",
    "            ch_pos_new[:,0] = ch_pos_new[:,0]+0.006\n",
    "            ch_pos_new = ch_pos_new*0.92\n",
    "            \n",
    "            new_montage = mne.channels.make_dig_montage(dict(zip(ch_names, ch_pos_new)), coord_frame='mri')\n",
    "            new_montage.add_estimated_fiducials(subject, subjects_dir)\n",
    "            \n",
    "            \n",
    "        else:\n",
    "        \n",
    "            new_montage = mne.channels.make_dig_montage(dict(zip(ch_names, ch_pos_new)), coord_frame='mri')\n",
    "            new_montage.add_estimated_fiducials(subject, subjects_dir)\n",
    "    \n",
    "            # Taliarach transform in FSURF_ folder\n",
    "            mri_mni_t = mne.read_talxfm(subject, subjects_dir)\n",
    "            new_montage.apply_trans(mri_mni_t)  # mri to mni_tal (MNI Taliarach)\n",
    "    \n",
    "            # transform to fsaverage\n",
    "            new_montage.apply_trans(mne.transforms.Transform(fro=\"mni_tal\", to=\"mri\", trans=np.eye(4)))\n",
    "        \n",
    "        \n",
    "        epochs.set_montage(new_montage)\n",
    "\n",
    "        # exclude channels from other hemisphere\n",
    "        if len(ch_names_right)==0:\n",
    "            pass\n",
    "        if len(ch_names_left)==0:\n",
    "            continue\n",
    "        else:\n",
    "            if hemi == 'right':\n",
    "                epochs.pick(list(ch_names_right))\n",
    "            elif hemi=='left':\n",
    "                epochs.pick(list(ch_names_left))\n",
    "            else:\n",
    "                print('hemi must be \"left\" or \"right\"') \n",
    "        \n",
    "        trans = mne.channels.compute_native_head_t(new_montage)\n",
    "                \n",
    "        # plot projected channels on fsaverage\n",
    "        brain.add_sensors(epochs.info, trans=trans, sensor_colors=colors, sensor_scales=0.003*median_df['size_factor'].values) #*median_df['size_factor'].values\n",
    "\n",
    "    lh = list(brain.plotter.actors.keys())[0]\n",
    "    rh = list(brain.plotter.actors.keys())[1]\n",
    "\n",
    "    \n",
    "    \n",
    "    if (hemi == 'right') & (view == 'lateral'):\n",
    "        brain.plotter.remove_actor(lh)\n",
    "        brain.show_view(azimuth=0)\n",
    "    elif (hemi == 'right') & (view == 'medial'):\n",
    "        brain.plotter.remove_actor(lh)\n",
    "        brain.show_view(azimuth=180, distance=0.38)\n",
    "    elif (hemi == 'left') & (view == 'lateral'):\n",
    "        brain.plotter.remove_actor(rh)\n",
    "        brain.show_view(azimuth=180)\n",
    "    elif (hemi == 'left') & (view == 'medial'):\n",
    "        brain.plotter.remove_actor(rh)\n",
    "        brain.show_view(azimuth=0, distance=0.38)\n",
    "        \n",
    "    # save image\n",
    "    # brain.save_image()\n",
    "        \n",
    "     \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a665c3-2ef5-4930-ab63-17a310142e3a",
   "metadata": {},
   "source": [
    "## panel A\n",
    "\n",
    "This panel contains sEEG electrode location information, and these data are available upon reasonable request, subject to IRB approval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6121f4e3-741e-4774-8545-c458e250b12f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "patients = ['1002', '1005', '1007', '1008', '1009', '1010', '1014']\n",
    "SDids = ['SD021', 'SD026', 'SD027', 'SD028', 'SD029', 'SD030', 'SD035']\n",
    "\n",
    "\n",
    "metrics = ['raw_btm_rho']\n",
    "hemis = ['left', 'right']\n",
    "views = ['lateral']\n",
    "\n",
    "for metric in metrics:\n",
    "    for hemi in hemis:\n",
    "        for view in views:\n",
    "            plot_brain_model_fits(patients, SDids, metric=metric, hemi=hemi, view=view)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb66d4d-3681-4790-918f-3749ef575fa9",
   "metadata": {},
   "source": [
    "## panel B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a125526b-b091-4140-aefc-2e299558b529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96014964-7186-458f-80f1-3f18f059f44e",
   "metadata": {},
   "source": [
    "## panel C\n",
    "\n",
    "This panel contains sEEG electrode location information, and these data are available upon reasonable request, subject to IRB approval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb875b30-56f2-42a9-8640-3a140b4eb08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = ['1002', '1005', '1007', '1008', '1009', '1010', '1014']\n",
    "SDids = ['SD021', 'SD026', 'SD027', 'SD028', 'SD029', 'SD030', 'SD035']\n",
    "\n",
    "\n",
    "metrics = ['raw_top_rho']\n",
    "hemis = ['left', 'right']\n",
    "views = ['lateral']\n",
    "\n",
    "for metric in metrics:\n",
    "    for hemi in hemis:\n",
    "        for view in views:\n",
    "            plot_brain_model_fits(patients, SDids, metric=metric, hemi=hemi, view=view)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae1c589-e3cc-4752-bf55-73a3f89fc05d",
   "metadata": {},
   "source": [
    "## panel D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c16ad2-25fd-4eb1-8045-1cf9a01a6ffb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "278a8704-cf22-420f-9b83-aa3d560f5458",
   "metadata": {},
   "source": [
    "## panel E\n",
    "\n",
    "This panel contains sEEG electrode location information, and these data are available upon reasonable request, subject to IRB approval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec307e45-901d-4ff3-9624-e5a995c57b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = ['1002', '1005', '1007', '1008', '1009', '1010', '1014']\n",
    "SDids = ['SD021', 'SD026', 'SD027', 'SD028', 'SD029', 'SD030', 'SD035']\n",
    "\n",
    "\n",
    "metrics = ['raw_SAM_y_rho',]\n",
    "hemis = ['left', 'right']\n",
    "views = ['lateral']\n",
    "\n",
    "for metric in metrics:\n",
    "    for hemi in hemis:\n",
    "        for view in views:\n",
    "            plot_brain_model_fits(patients, SDids, metric=metric, hemi=hemi, view=view)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f8ab34-caba-46f5-943e-530249b07b64",
   "metadata": {},
   "source": [
    "## panel F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fddf43a-db40-4b8d-8486-eb65e7fbc8c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94d7a5c9-dd6f-4af0-983a-7f361720dcfa",
   "metadata": {},
   "source": [
    "## panel G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2897598-2edc-4a7e-aac8-b59924ef6f56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
